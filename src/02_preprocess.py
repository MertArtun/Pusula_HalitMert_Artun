#!/usr/bin/env python3
"""
Fiziksel TÄ±p & Rehabilitasyon Veri Analizi - Veri Temizleme ve Ã–n Ä°ÅŸleme

Bu script Excel verisini okur, temizler ve model iÃ§in hazÄ±r hale getirir.
Ä°ki farklÄ± Ã§Ä±ktÄ± Ã¼retir:
1. clean_minimal.csv: Temel temizlik uygulanmÄ±ÅŸ veri
2. model_ready_minimal.csv: Eksik deÄŸer iÅŸleme uygulanmÄ±ÅŸ model-ready veri

KullanÄ±m:
    python src/02_preprocess.py --excel-path data/Talent_Academy_Case_DT_2025.xlsx --sheet Sheet1
"""

import argparse
import os
import sys
import pandas as pd
import numpy as np
from pathlib import Path
from sklearn.impute import SimpleImputer, KNNImputer

# utils modÃ¼lÃ¼nÃ¼ import et
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from utils import (
    parse_tedavi_suresi_to_int,
    parse_sure_to_minutes,
    split_list,
    add_count_columns,
    ensure_directory_exists
)
from common_logging import preprocess_logger as logger


def load_data(excel_path: str, sheet_name: str) -> pd.DataFrame:
    """
    Excel dosyasÄ±ndan veriyi yÃ¼kler.
    
    Args:
        excel_path (str): Excel dosya yolu
        sheet_name (str): Sheet adÄ±
        
    Returns:
        pd.DataFrame: YÃ¼klenen veri
    """
    try:
        df = pd.read_excel(excel_path, sheet_name=sheet_name)
        logger.info(f"âœ… Veri baÅŸarÄ±yla yÃ¼klendi: {df.shape[0]} satÄ±r, {df.shape[1]} sÃ¼tun")
        return df
    except FileNotFoundError:
        logger.error(f"âŒ Hata: Excel dosyasÄ± bulunamadÄ±: {excel_path}")
        sys.exit(1)
    except Exception as e:
        logger.error(f"âŒ Hata: Excel dosyasÄ± okunurken hata oluÅŸtu: {e}")
        sys.exit(1)


def apply_data_transformations(df: pd.DataFrame) -> pd.DataFrame:
    """
    Temel veri dÃ¶nÃ¼ÅŸÃ¼mlerini uygular.
    
    Args:
        df (pd.DataFrame): Ham veri
        
    Returns:
        pd.DataFrame: DÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ veri
    """
    df_clean = df.copy()
    
    logger.info("ğŸ”„ Veri dÃ¶nÃ¼ÅŸÃ¼mleri uygulanÄ±yor...")
    
    # 1. Hedef deÄŸiÅŸken dÃ¶nÃ¼ÅŸÃ¼mÃ¼
    if 'TedaviSuresi' in df_clean.columns:
        df_clean['TedaviSuresi_num'] = df_clean['TedaviSuresi'].apply(
            parse_tedavi_suresi_to_int
        )
        successful_parse = df_clean['TedaviSuresi_num'].notna().sum()
        print(f"   âœ… TedaviSuresi â†’ TedaviSuresi_num: {successful_parse}/{len(df_clean)} baÅŸarÄ±lÄ±")
    
    # 2. Uygulama sÃ¼resi dÃ¶nÃ¼ÅŸÃ¼mÃ¼
    if 'UygulamaSuresi' in df_clean.columns:
        df_clean['UygulamaSuresi_dk'] = df_clean['UygulamaSuresi'].apply(
            parse_sure_to_minutes
        )
        successful_parse = df_clean['UygulamaSuresi_dk'].notna().sum()
        print(f"   âœ… UygulamaSuresi â†’ UygulamaSuresi_dk: {successful_parse}/{len(df_clean)} baÅŸarÄ±lÄ±")
    
    # 3. Ã‡oklu deÄŸerli alanlar iÃ§in sayÄ± sÃ¼tunlarÄ±
    multi_value_columns = ['KronikHastalik', 'Alerji', 'Tanilar', 'UygulamaYerleri']
    existing_multi_cols = [col for col in multi_value_columns if col in df_clean.columns]
    
    if existing_multi_cols:
        df_clean = add_count_columns(df_clean, existing_multi_cols)
        print(f"   âœ… Ã‡oklu deÄŸerli alan sayÄ±larÄ± eklendi: {existing_multi_cols}")
    
    # 4. YaÅŸ sÃ¼tununu sayÄ±sal yap
    if 'Yas' in df_clean.columns:
        df_clean['Yas'] = pd.to_numeric(df_clean['Yas'], errors='coerce')
        print(f"   âœ… YaÅŸ sÃ¼tunu sayÄ±sal formata dÃ¶nÃ¼ÅŸtÃ¼rÃ¼ldÃ¼")
    
    return df_clean


def create_clean_minimal(df: pd.DataFrame) -> pd.DataFrame:
    """
    TemizlenmiÅŸ minimal veri seti oluÅŸturur.
    Hedefi NaN olan satÄ±rlarÄ± Ã§Ä±karÄ±r.
    
    Args:
        df (pd.DataFrame): DÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ veri
        
    Returns:
        pd.DataFrame: TemizlenmiÅŸ minimal veri
    """
    print("ğŸ§¹ TemizlenmiÅŸ minimal veri seti oluÅŸturuluyor...")
    
    df_clean = df.copy()
    
    # Hedef deÄŸiÅŸkeni NaN olan satÄ±rlarÄ± Ã§Ä±kar
    if 'TedaviSuresi_num' in df_clean.columns:
        initial_count = len(df_clean)
        df_clean = df_clean[df_clean['TedaviSuresi_num'].notna()]
        removed_count = initial_count - len(df_clean)
        print(f"   ğŸ“Š Hedef deÄŸiÅŸkeni eksik olan {removed_count} satÄ±r Ã§Ä±karÄ±ldÄ±")
        print(f"   ğŸ“Š Kalan satÄ±r sayÄ±sÄ±: {len(df_clean)}")
    
    return df_clean


def apply_imputation(df: pd.DataFrame, imputer_type: str = "median") -> pd.DataFrame:
    """
    Eksik deÄŸer iÅŸleme (imputation) uygular.
    
    Args:
        df (pd.DataFrame): TemizlenmiÅŸ veri
        imputer_type (str): "median" veya "knn"
        
    Returns:
        pd.DataFrame: Imputation uygulanmÄ±ÅŸ veri
    """
    print("ğŸ”§ Eksik deÄŸer iÅŸleme uygulanÄ±yor...")
    
    df_imputed = df.copy()
    
    # SayÄ±sal sÃ¼tunlar iÃ§in imputation
    numeric_columns = df_imputed.select_dtypes(include=[np.number]).columns
    numeric_columns = [col for col in numeric_columns if col != 'HastaNo']  # ID sÃ¼tununu hariÃ§ tut
    
    if len(numeric_columns) > 0:
        if imputer_type == "median":
            print(f"   ğŸ”¢ SayÄ±sal sÃ¼tunlar iÃ§in median imputation: {list(numeric_columns)}")
            
            for col in numeric_columns:
                missing_count = df_imputed[col].isnull().sum()
                if missing_count > 0:
                    median_value = df_imputed[col].median()
                    df_imputed[col] = df_imputed[col].fillna(median_value)
                    print(f"      - {col}: {missing_count} eksik deÄŸer {median_value} ile dolduruldu")
        
        elif imputer_type == "knn":
            print(f"   ğŸ”¢ SayÄ±sal sÃ¼tunlar iÃ§in KNN imputation: {list(numeric_columns)}")
            
            # Eksik deÄŸeri olan sÃ¼tunlarÄ± kontrol et
            missing_cols = [col for col in numeric_columns if df_imputed[col].isnull().sum() > 0]
            
            if missing_cols:
                # KNNImputer uygula
                knn_imputer = KNNImputer(n_neighbors=5, weights="uniform")
                df_imputed[numeric_columns] = knn_imputer.fit_transform(df_imputed[numeric_columns])
                
                for col in missing_cols:
                    missing_count = df[col].isnull().sum()  # Orijinal eksik sayÄ±sÄ±
                    print(f"      - {col}: {missing_count} eksik deÄŸer KNN ile dolduruldu")
            else:
                print(f"      - SayÄ±sal sÃ¼tunlarda eksik deÄŸer yok")
    
    # Kategorik sÃ¼tunlar iÃ§in "Bilinmiyor" ile doldur
    categorical_columns = [
        'Cinsiyet', 'KanGrubu', 'Uyruk', 'Bolum', 'TedaviAdi'
    ]
    existing_cat_cols = [col for col in categorical_columns if col in df_imputed.columns]
    
    if existing_cat_cols:
        print(f"   ğŸ“ Kategorik sÃ¼tunlar iÃ§in 'Bilinmiyor' ile doldurma: {existing_cat_cols}")
        
        for col in existing_cat_cols:
            missing_count = df_imputed[col].isnull().sum()
            if missing_count > 0:
                df_imputed[col] = df_imputed[col].fillna('Bilinmiyor')
                print(f"      - {col}: {missing_count} eksik deÄŸer 'Bilinmiyor' ile dolduruldu")
    
    # Ã‡oklu deÄŸerli sÃ¼tunlar iÃ§in boÅŸ string ile doldur
    multi_value_columns = ['KronikHastalik', 'Alerji', 'Tanilar', 'UygulamaYerleri']
    existing_multi_cols = [col for col in multi_value_columns if col in df_imputed.columns]
    
    if existing_multi_cols:
        print(f"   ğŸ“‹ Ã‡oklu deÄŸerli sÃ¼tunlar iÃ§in boÅŸ string ile doldurma: {existing_multi_cols}")
        
        for col in existing_multi_cols:
            missing_count = df_imputed[col].isnull().sum()
            if missing_count > 0:
                df_imputed[col] = df_imputed[col].fillna('')
                print(f"      - {col}: {missing_count} eksik deÄŸer boÅŸ string ile dolduruldu")
    
    # DiÄŸer string sÃ¼tunlarÄ± iÃ§in "Bilinmiyor" ile doldur
    string_columns = df_imputed.select_dtypes(include=['object']).columns
    remaining_string_cols = [col for col in string_columns 
                           if col not in existing_cat_cols + existing_multi_cols + ['TedaviSuresi', 'UygulamaSuresi']]
    
    if remaining_string_cols:
        print(f"   ğŸ“„ DiÄŸer string sÃ¼tunlar iÃ§in 'Bilinmiyor' ile doldurma: {remaining_string_cols}")
        
        for col in remaining_string_cols:
            missing_count = df_imputed[col].isnull().sum()
            if missing_count > 0:
                df_imputed[col] = df_imputed[col].fillna('Bilinmiyor')
                print(f"      - {col}: {missing_count} eksik deÄŸer 'Bilinmiyor' ile dolduruldu")
    
    return df_imputed


def validate_processed_data(df_clean: pd.DataFrame, df_model_ready: pd.DataFrame) -> None:
    """
    Ä°ÅŸlenmiÅŸ verileri doÄŸrular ve rapor verir.
    
    Args:
        df_clean (pd.DataFrame): TemizlenmiÅŸ veri
        df_model_ready (pd.DataFrame): Model-ready veri
    """
    print("\nğŸ“‹ Veri Ä°ÅŸleme DoÄŸrulama Raporu:")
    print("=" * 50)
    
    # Temel istatistikler
    print(f"ğŸ“Š Clean Minimal - SatÄ±r: {len(df_clean):,}, SÃ¼tun: {len(df_clean.columns)}")
    print(f"ğŸ“Š Model Ready - SatÄ±r: {len(df_model_ready):,}, SÃ¼tun: {len(df_model_ready.columns)}")
    
    # Eksik deÄŸer kontrolÃ¼
    clean_missing = df_clean.isnull().sum().sum()
    model_missing = df_model_ready.isnull().sum().sum()
    
    print(f"\nğŸ” Eksik DeÄŸer KontrolÃ¼:")
    print(f"   Clean Minimal: {clean_missing:,} eksik deÄŸer")
    print(f"   Model Ready: {model_missing:,} eksik deÄŸer")
    
    # Hedef deÄŸiÅŸken kontrolÃ¼
    if 'TedaviSuresi_num' in df_clean.columns:
        target_stats_clean = df_clean['TedaviSuresi_num'].describe()
        target_stats_model = df_model_ready['TedaviSuresi_num'].describe()
        
        print(f"\nğŸ¯ Hedef DeÄŸiÅŸken Ä°statistikleri:")
        print(f"   Clean Minimal - Min: {target_stats_clean['min']:.1f}, "
              f"Max: {target_stats_clean['max']:.1f}, "
              f"Ortalama: {target_stats_clean['mean']:.2f}")
        print(f"   Model Ready - Min: {target_stats_model['min']:.1f}, "
              f"Max: {target_stats_model['max']:.1f}, "
              f"Ortalama: {target_stats_model['mean']:.2f}")
    
    # Veri tipleri
    print(f"\nğŸ“‹ Veri Tipleri:")
    for dtype in ['int64', 'float64', 'object']:
        clean_count = len(df_clean.select_dtypes(include=[dtype]).columns)
        model_count = len(df_model_ready.select_dtypes(include=[dtype]).columns)
        print(f"   {dtype}: Clean={clean_count}, Model Ready={model_count}")


def save_processed_data(df_clean: pd.DataFrame, df_model_ready: pd.DataFrame, output_dir: str) -> None:
    """
    Ä°ÅŸlenmiÅŸ verileri kaydeder.
    
    Args:
        df_clean (pd.DataFrame): TemizlenmiÅŸ veri
        df_model_ready (pd.DataFrame): Model-ready veri
        output_dir (str): Ã‡Ä±ktÄ± dizini
    """
    ensure_directory_exists(output_dir)
    
    # Clean minimal kaydet
    clean_path = os.path.join(output_dir, 'clean_minimal.csv')
    df_clean.to_csv(clean_path, index=False, encoding='utf-8-sig')
    print(f"âœ… Clean minimal veri kaydedildi: {clean_path}")
    
    # Model ready kaydet
    model_ready_path = os.path.join(output_dir, 'model_ready_minimal.csv')
    df_model_ready.to_csv(model_ready_path, index=False, encoding='utf-8-sig')
    print(f"âœ… Model-ready veri kaydedildi: {model_ready_path}")
    
    # SÃ¼tun bilgileri kaydet
    column_info_path = os.path.join(output_dir, 'column_info.csv')
    column_info = pd.DataFrame({
        'sutun_adi': df_model_ready.columns,
        'veri_tipi': [str(df_model_ready[col].dtype) for col in df_model_ready.columns],
        'eksik_deger_sayisi': [df_model_ready[col].isnull().sum() for col in df_model_ready.columns],
        'benzersiz_deger_sayisi': [df_model_ready[col].nunique() for col in df_model_ready.columns]
    })
    
    column_info.to_csv(column_info_path, index=False, encoding='utf-8-sig')
    print(f"âœ… SÃ¼tun bilgileri kaydedildi: {column_info_path}")


def main():
    """Ana fonksiyon - komut satÄ±rÄ± argÃ¼manlarÄ±nÄ± iÅŸler ve veri temizleme yapar."""
    parser = argparse.ArgumentParser(
        description="Fiziksel TÄ±p & Rehabilitasyon Veri Analizi - Veri Temizleme Script",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Ã–rnekler:
  python src/02_preprocess.py --excel-path data/Talent_Academy_Case_DT_2025.xlsx --sheet Sheet1
  python src/02_preprocess.py --excel-path data/veri.xlsx --sheet "Veri SayfasÄ±"

Ã‡Ä±ktÄ±lar:
  - data/processed/clean_minimal.csv: Temel temizlik uygulanmÄ±ÅŸ veri
  - data/processed/model_ready_minimal.csv: Model iÃ§in hazÄ±r veri (imputation uygulanmÄ±ÅŸ)
  - data/processed/column_info.csv: SÃ¼tun bilgileri
        """
    )
    
    parser.add_argument(
        '--excel-path',
        required=True,
        help='Excel dosya yolu (Ã¶rn: data/Talent_Academy_Case_DT_2025.xlsx)'
    )
    
    parser.add_argument(
        '--sheet',
        default='Sheet1',
        help='Excel sheet adÄ± (varsayÄ±lan: Sheet1)'
    )
    
    parser.add_argument(
        '--imputer',
        choices=['median', 'knn'],
        default='median',
        help='SayÄ±sal eksik deÄŸer doldurma yÃ¶ntemi (varsayÄ±lan: median)'
    )
    
    args = parser.parse_args()
    
    logger.info("ğŸš€ Fiziksel TÄ±p & Rehabilitasyon Veri Temizleme Script'i BaÅŸlatÄ±lÄ±yor...")
    logger.info(f"ğŸ“ Excel DosyasÄ±: {args.excel_path}")
    logger.info(f"ğŸ“„ Sheet: {args.sheet}")
    logger.info(f"ğŸ”§ Imputer: {args.imputer}")
    
    # Ã‡Ä±ktÄ± dizinini hazÄ±rla
    output_dir = 'data/processed'
    ensure_directory_exists(output_dir)
    
    # Veriyi yÃ¼kle
    df = load_data(args.excel_path, args.sheet)
    
    # Veri dÃ¶nÃ¼ÅŸÃ¼mlerini uygula
    df_transformed = apply_data_transformations(df)
    
    # Clean minimal veri seti oluÅŸtur
    df_clean = create_clean_minimal(df_transformed)
    
    # Model-ready veri seti iÃ§in imputation uygula
    df_model_ready = apply_imputation(df_clean, args.imputer)
    
    # DoÄŸrulama
    validate_processed_data(df_clean, df_model_ready)
    
    # Verileri kaydet
    logger.info("ğŸ’¾ Veriler kaydediliyor...")
    save_processed_data(df_clean, df_model_ready, output_dir)
    
    logger.info("âœ… Veri temizleme tamamlandÄ±!")
    logger.info(f"ğŸ“ Ã‡Ä±ktÄ± dosyalarÄ±: {output_dir}/")
    logger.info("   - clean_minimal.csv: Temel temizlik uygulanmÄ±ÅŸ veri")
    logger.info("   - model_ready_minimal.csv: Model iÃ§in hazÄ±r veri")
    logger.info("   - column_info.csv: SÃ¼tun bilgileri")


if __name__ == "__main__":
    main()
